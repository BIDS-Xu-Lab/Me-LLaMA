{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0390a82a-3fe3-484d-a4ba-d8777e74c047",
   "metadata": {},
   "source": [
    "# GENERAL DOMAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e93159-cad9-4f73-9b66-dc3ea3d209e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "# Huggingface token\n",
    "token = ''\n",
    "\n",
    "# Cache path\n",
    "local_cache_path = ''\n",
    "\n",
    "# Saved json file path\n",
    "saved_json_file = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a5467-02c2-41e9-a843-e9cc6fbb1e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dataset = load_dataset('HuggingFaceFW/fineweb' ,'sample-100BT',streaming = True,split = 'train',cache_dir = local_cache_path, token = token)\n",
    "shuffled_dataset = local_dataset.shuffle(seed = 42, buffer_size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784e6ef-dc75-4c98-9969-0a64526c6d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 0\n",
    "m = 0\n",
    "\n",
    "# token needed for general domain\n",
    "token_needed = 14497666456\n",
    "\n",
    "with open(saved_json_file,'a') as fw:\n",
    "    for i in shuffled_dataset:\n",
    "\n",
    "        m+=1\n",
    "        if token <= token_needed: \n",
    "            text = i['text']\n",
    "            token += i['token_count']\n",
    "            data = {'text': f'{text}'}\n",
    "            fw.write(json.dumps(data) + '\\n')\n",
    "\n",
    "            if m%1000000 == 0:\n",
    "                print(token/token_needed)\n",
    "\n",
    "        else:\n",
    "            print('done')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2dc883-12d3-43ed-b588-081316114c80",
   "metadata": {},
   "source": [
    "# BIO DOMAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "328a2ce0-dee7-480d-9c5e-b695578031b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3748a7c2354539881b18a2c9950135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ca52c2c90f4fe3b85f0aadc1b64312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "data1 = 'epfl-llm/guidelines'\n",
    "data2 = 'health360/Healix-Shot'\n",
    "\n",
    "local_dataset1 = load_dataset(data1,cache_dir = local_cache_path)['train']\n",
    "local_dataset2 = load_dataset(data2,cache_dir = local_cache_path)['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d474e79c-7d62-453f-87ef-89a9c7339316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data1---epfl-llm/guidelines\n",
    "#data2---health360/Healix-Shot\n",
    "\n",
    "import json\n",
    "with open(saved_json_file,'a') as f:\n",
    "    for i in local_dataset1['train']:\n",
    "        \n",
    "        text = i['clean_text']  # for data1, use i['clean_text']; for data2, use i['text']\n",
    "        \n",
    "        data = {'text': f'{text}'}\n",
    "        f.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed0561-e69b-4dd0-aee2-c4169c7f9ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For text with jsonl format.\n",
    "# text3---the-pile-pubmed-central-refine-result.jsonl\n",
    "# text4---the-pile-pubmed-abstract-refine-result.jsonl\n",
    "# text5---\n",
    "data3_path = ''\n",
    "\n",
    "import json\n",
    "with open(data3_path, 'r') as file, open(saved_json_file,'a') as fw:\n",
    "    k = 0\n",
    "    for line in file:\n",
    "        if k%50000 == 0:\n",
    "            print(1)\n",
    "        k+=1\n",
    "        data_line = json.loads(line)\n",
    "        \n",
    "        text = data_line['text']\n",
    "        data = {'text': f'{text}'}\n",
    "        fw.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93f82b-104e-4f6d-99f8-9b9137e9c5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e22818d-d698-4ce0-a69c-37d5c501f0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8371f944-2f0e-42b2-9f1e-5fe2dfb24c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f79e1-1b25-4e04-bb53-abfa8e74861e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e11ad3-804c-4d3d-8a64-a724680b5e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f84194-7075-462b-a840-68abdb02b046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
